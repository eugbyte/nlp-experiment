{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+unBk2OMTjD3trh7Rcmli",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eugbyte/nlp-experiment/blob/main/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6p3F0HGaNPt"
      },
      "source": [
        "import numpy as np\r\n",
        "import re\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.models import Sequential, Model\r\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM, Embedding, GRU, Bidirectional\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pds\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from spacy.lang.en import English\r\n",
        "import spacy\r\n",
        "import json\r\n",
        "import nltk\r\n",
        "from nltk import tokenize\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from google.colab import files\r\n",
        "import os\r\n",
        "from keras.optimizers import Adam, SGD"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4R3YM3da6Ji"
      },
      "source": [
        "# Import files from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfWQZG5raRkO",
        "outputId": "a7885cf2-784f-4731-f154-d2df764b69b1"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJaHElwPaSNY",
        "outputId": "bfba251e-728f-4e8d-9089-cb9e7f3aae73"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Colab Notebooks/"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLk2jV_7aUAv",
        "outputId": "d5ab003f-398c-4863-fea4-c6f4568015bb"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bi-lstm.ipynb\t\t\t\t    poetry-generation.ipynb\n",
            " Chatbot\t\t\t\t    poetry.h5\n",
            " Chatbot_squad_v5.ipynb\t\t\t    robert_frost.txt\n",
            "'Copy of bi-lstm.ipynb'\t\t\t    seq2seq.ipynb\n",
            "'Copy of C4W3_Colab_T5_SQuAD_Model.ipynb'   spa.txt\n",
            " glove.6B.50d.txt\t\t\t    Tutorials\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLfGC7yWa_u-"
      },
      "source": [
        "# Constants Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thIYwoyMaiAd"
      },
      "source": [
        "# some configuration\r\n",
        "MAX_SEQUENCE_LENGTH = 100\r\n",
        "MAX_VOCAB_SIZE = 3000\r\n",
        "EMBEDDING_DIM = 50\r\n",
        "VALIDATION_SPLIT = 0.2\r\n",
        "BATCH_SIZE = 128\r\n",
        "LATENT_DIM = 25\r\n",
        "MAX_NUM_WORDS=20000\r\n",
        "\r\n",
        "NUM_SAMPLES = 1000\r\n",
        "EPOCHS = 50"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRcqlffSbfeY"
      },
      "source": [
        "# Load in input texts, target texts, and teacher forced texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6PatoPOaig9"
      },
      "source": [
        "# load in the data\r\n",
        "input_texts = []\r\n",
        "target_texts = []\r\n",
        "target_texts_inputs = [] # for teacher forcing, i.e. target_texts offset by 1"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSovAGYVarID"
      },
      "source": [
        "i = 0\r\n",
        "\r\n",
        "for line in open('spa.txt'):\r\n",
        "\r\n",
        "  i += 1\r\n",
        "  \r\n",
        "  # will take too long otherwise\r\n",
        "  # also, in datasets, longer sentences ordered at the end\r\n",
        "  # the longer the setence, the more the unnecessary paddings\r\n",
        "  if i > NUM_SAMPLES:\r\n",
        "    break\r\n",
        "\r\n",
        "  if '\\t' not in line:\r\n",
        "    continue\r\n",
        "\r\n",
        "  input_text, translation = line.split(\"\\t\")\r\n",
        "\r\n",
        "  line = line.rstrip()\r\n",
        "  if not line:\r\n",
        "    continue\r\n",
        "\r\n",
        "  input_line = '<sos> ' + line\r\n",
        "  target_line = line + ' <eos>'\r\n",
        "  target_texts_input = '<sos> ' + target_line  # teacher forcing\r\n",
        "\r\n",
        "  input_texts.append(input_line)\r\n",
        "  target_texts.append(target_line)\r\n",
        "  target_texts_inputs.append(target_texts_input)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnAor_Shcgda",
        "outputId": "7b23828d-b3da-46a1-c2f0-15297b67ec36"
      },
      "source": [
        "print(\"num samples\", len(input_texts))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdsGtFQg9svN",
        "outputId": "cd103aa0-d777-4696-8f13-82f6b6964007"
      },
      "source": [
        "print(\"num samples\", len(target_texts))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddJTXreObqjM"
      },
      "source": [
        "# Tokenize the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtmvNadVcj4S"
      },
      "source": [
        "# tokenize the sentences\r\n",
        "# you need tokenizers as you have 2 different languages"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFGpP_81cujo"
      },
      "source": [
        "# the input tokenizer\r\n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS, filters=\"\")\r\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\r\n",
        "input_sequences =  tokenizer_inputs.texts_to_sequences(input_texts)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3O4BXFbdTeI",
        "outputId": "54852b6f-b0a2-48b2-f4bf-321d1bdd6a64"
      },
      "source": [
        "word2idx_input = tokenizer_inputs.word_index\r\n",
        "print(\"Len of input word index\", len(word2idx_input))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Len of input word index 1547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6jMLHbldgHP",
        "outputId": "e224eea2-07e9-4259-9ebd-545e41ed7de8"
      },
      "source": [
        "max_len_input = max(len(s) for s in input_sequences)\r\n",
        "print(max_len_input)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eODz94sddpKC"
      },
      "source": [
        "# tokenize the output\r\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters=\"\")\r\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\r\n",
        "target_sequences =  tokenizer_inputs.texts_to_sequences(target_texts)\r\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfqgvbTFeZDC",
        "outputId": "c1515f70-b996-4a6b-ea7e-7c25f8c8fa4e"
      },
      "source": [
        "word2idx_outputs = tokenizer_outputs.word_index\r\n",
        "print(\"Len of output word index\", len(word2idx_input))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Len of output word index 1547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8hN6shLelL7"
      },
      "source": [
        "# store number of words for later\r\n",
        "# remember to add 1 since indexing starts at 1. <sos> is at index 0\r\n",
        "\r\n",
        "num_words_output = len(word2idx_outputs) + 1"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do9_DykW5_fZ",
        "outputId": "822637c0-0fc6-4ebd-8392-021e05db8e02"
      },
      "source": [
        "num_words_output"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXiA6wdve-TY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d2ab7b-bcf6-4760-87c3-eee81b70272d"
      },
      "source": [
        "# determine the maximum length output sequence\r\n",
        "\r\n",
        "max_len_target = max(len(s) for s in target_sequences)\r\n",
        "print(max_len_target)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfTi1ydgfPWY"
      },
      "source": [
        "# pad the input, target, target_inputs sequences"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciqBKHHPfX4G",
        "outputId": "c6b56a82-038e-4edd-ee5d-0a5a180ee730"
      },
      "source": [
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input, padding=\"post\")\r\n",
        "print(encoder_inputs.shape)\r\n",
        "print(encoder_inputs[0])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 8)\n",
            "[  1 354   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukHZnVHnghKw",
        "outputId": "90da65a5-280a-4c53-8cea-6538e0ed19df"
      },
      "source": [
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding=\"post\")\r\n",
        "print(decoder_inputs.shape)\r\n",
        "print(decoder_inputs[0])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 7)\n",
            "[  2 355   1   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1vbFj4XhDKs",
        "outputId": "1ba3d2ed-3742-497e-a345-aec35ea1c9a2"
      },
      "source": [
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding=\"post\")\r\n",
        "print(decoder_targets.shape)\r\n",
        "print(decoder_targets[0])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 7)\n",
            "[354   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh3001flb35I"
      },
      "source": [
        "# Prepare pre-trained embedding matrix with Glove\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKCOYevVhbGZ",
        "outputId": "51da86a0-f574-4b74-ece1-0bbc35f189c8"
      },
      "source": [
        "# load in pre-trained word vectors\r\n",
        "\r\n",
        "word2vec = {}\r\n",
        "\r\n",
        "print('Loading word vectors...')\r\n",
        "\r\n",
        "file_path = f'glove.6B.{EMBEDDING_DIM}d.txt'\r\n",
        "with open(file_path) as f:\r\n",
        "  # is just a space-separated text file in the format:\r\n",
        "  # word vec[0] vec[1] vec[2] ...\r\n",
        "  for line in f:\r\n",
        "    values = line.split()\r\n",
        "    word = values[0]\r\n",
        "    vec = np.asarray(values[1:], dtype='float32')\r\n",
        "    word2vec[word] = vec\r\n",
        "print('Found %s word vectors.' % len(word2vec))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdh4emMPhjSx",
        "outputId": "5431f161-df0b-4c10-cec0-2257408054d8"
      },
      "source": [
        "# Prepare pre-trained embedding matrix\r\n",
        "# Instead of a regular embedding matrix, where each cell is a numerical word_token corresponding to word_index, \r\n",
        "# each row is a pre-trained vector\r\n",
        "\r\n",
        "num_words = len(word2idx_outputs) + 1 # word index start from 1 after <sos> token\r\n",
        "\r\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\r\n",
        "\r\n",
        "print(embedding_matrix.shape) # words by feture dimensions\r\n",
        "print(embedding_matrix[0:2])\r\n",
        "print(embedding_matrix[0].shape)\r\n",
        "\r\n",
        "# now the embedding matrix is 3d\r\n",
        "for word, i in word2idx_outputs.items():\r\n",
        "  if i < MAX_VOCAB_SIZE:\r\n",
        "    embedding_vector = word2vec.get(word) # get returns None instead of throwing error if key does not exist\r\n",
        "    if embedding_vector is not None:\r\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1549, 50)\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n",
            "(50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6AnSWxWiXOd",
        "outputId": "1e5053d2-805a-4c36-8784-46b2feeecd57"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1549, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCk-mh3EcBWo"
      },
      "source": [
        "# One hot encode the target vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ENnsnL6pJ1",
        "outputId": "94ee6399-a3be-4762-e34d-629d92c90a67"
      },
      "source": [
        "print(len(input_texts), max_len_target, num_words_output)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 7 1549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPnJ1XfIiYyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb5ff4c-5ce5-4c05-8904-2944c410e8bf"
      },
      "source": [
        "# one-hot the targets (can't use sparse cross-entropy, since output is more than 2d). We get a sequence\r\n",
        "\r\n",
        "# dimension will be num samples x max_sequence_len x num words. \r\n",
        "\r\n",
        "one_hot_targets = np.zeros((len(input_texts), max_len_target, num_words_output))  \r\n",
        "print(one_hot_targets.shape)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 7, 1549)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsbuEMKv-Muk"
      },
      "source": [
        "# for every target sequence, for every word_token in that sequence ...\r\n",
        "for i, target_sequence in enumerate(target_sequences):\r\n",
        "  for t, word_token in enumerate(target_sequence):\r\n",
        "    if word_token > 0:     # 0 used for padding\r\n",
        "      one_hot_targets[i, t, word_token] = 1"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIr3I32LcNu3"
      },
      "source": [
        "# Build the training model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0tE4XywchA-"
      },
      "source": [
        "1.   Note that the training model includes both the encoder RNN layer, followed by the decoder RNN layer\r\n",
        "2.   We discard the outputs of the encoder RNN, only saving the state\r\n",
        "3.   The decoder RNN reuses this state for teacher forcing.\r\n",
        "4.  Effectively, the decoder learns to generate targets[t+1...] given targets[...t], conditioned on the input sequence\r\n",
        "5.   Because the training process and inference process (decoding sentences) are quite different, we use different models for both, albeit they all leverage the same inner layers.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi0ZVLPKg__s"
      },
      "source": [
        "## Build the encoder layer\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daH8jVmQJeDt"
      },
      "source": [
        "encoder_inputs_placeholder = Input(shape=(max_len_input, ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bH4jXLHil8Y"
      },
      "source": [
        "# load pre-trained word embedding into a single LSTM layer\r\n",
        "# for pre-training, need to specify the weights\r\n",
        "# also need to specify that this first layer should not be retrained since the weights have already been calculated for us\r\n",
        "embedding_layer = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix], trainable=False)  "
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzynFgbEiaMF"
      },
      "source": [
        "x = embedding_layer(encoder_inputs_placeholder)\r\n",
        "encoder = LSTM(LATENT_DIM, return_state=True, dropout=0.5)\r\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQCC1qxYcaa9"
      },
      "source": [
        "## Save the thought vector for the decoder layer\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP2POl3H0j_g"
      },
      "source": [
        "# retain the state to pass to the decoder\r\n",
        "# c represents the cell state, i.e. weights - you don't keras to generate the weights randomly\r\n",
        "# h is the hidden state, i.e. the prediction at the latest time step. h is the same as encoder_outputs here\r\n",
        "encoder_outputs, h, c = encoder(x)\r\n",
        "encoder_states = [h, c]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlGebFmO1X4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8255335-3bfb-4b61-8826-1ea32085d4f6"
      },
      "source": [
        "print(encoder_outputs.shape, h.shape, c.shape)\r\n",
        "print(encoder_outputs[0], h[0])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 25) (None, 25) (None, 25)\n",
            "KerasTensor(type_spec=TensorSpec(shape=(25,), dtype=tf.float32, name=None), name='tf.__operators__.getitem_2/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_2'\") KerasTensor(type_spec=TensorSpec(shape=(25,), dtype=tf.float32, name=None), name='tf.__operators__.getitem_3/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_3'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIq7l8lYhHS6"
      },
      "source": [
        "## Build the decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyzCK-r10_d0"
      },
      "source": [
        "# build the decoder layer\r\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target, ))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Bkbvo5_YoP",
        "outputId": "3172f4be-17d4-48dc-d709-71abfbe3ebbf"
      },
      "source": [
        "decoder_inputs_placeholder.shape"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWbFSlYl1mEK"
      },
      "source": [
        "# use new embedding layer since you are using a new language\r\n",
        "decoder_embedding = Embedding(num_words_output, LATENT_DIM) # decoder_embedding layer will not use pre-trained word vectors\r\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\r\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8z_2mJUwwk2"
      },
      "source": [
        "# since the decoder is a to-many model, we want return-sequences = True\r\n",
        "# many sentences are translated to many sentences\r\n",
        "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, dropout=0.5)\r\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlHvBkw4xY4B"
      },
      "source": [
        "# final dense layer for prediction\r\n",
        "decoder_dense = Dense(num_words_output, activation=\"softmax\")\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke0r3J6RiHoh"
      },
      "source": [
        "## Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyWpZ-cP0OE2"
      },
      "source": [
        "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t92yot9a0aEU"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXb7qyIM-YCU",
        "outputId": "d4687aa9-6903-4ed4-a82c-f0f79fa7d21a"
      },
      "source": [
        "encoder_inputs.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T913j0b8-kme",
        "outputId": "bee992f4-4b24-4545-8570-ea09db16e0d3"
      },
      "source": [
        "max_len_input"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBVOr3U0-qj3",
        "outputId": "8e8da43e-a249-4ab6-8716-be1862f7e78d"
      },
      "source": [
        "decoder_inputs.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsoQmSDX-s7c",
        "outputId": "56a0022e-d9d3-4495-a662-0d7164b539cd"
      },
      "source": [
        "max_len_target"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMtx7Ivo1rUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757cfe05-e255-49ab-8a12-3b5a696fc83d"
      },
      "source": [
        "r = model.fit([encoder_inputs, decoder_inputs], one_hot_targets, # [english sentences, teacher forced senteces], target sentences\r\n",
        "              batch_size=BATCH_SIZE,\r\n",
        "              epochs=EPOCHS,\r\n",
        "              validation_split=0.2)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 4s 161ms/step - loss: 3.2334 - accuracy: 0.0037 - val_loss: 3.7240 - val_accuracy: 0.0050\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 3.2237 - accuracy: 0.0153 - val_loss: 3.6994 - val_accuracy: 0.0036\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 3.1952 - accuracy: 0.0187 - val_loss: 3.6653 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 3.0765 - accuracy: 0.0152 - val_loss: 3.6442 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 3.0275 - accuracy: 0.0134 - val_loss: 3.6338 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.9423 - accuracy: 0.0124 - val_loss: 3.6292 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 2.9709 - accuracy: 0.0144 - val_loss: 3.6289 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 2.9228 - accuracy: 0.0151 - val_loss: 3.6321 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8918 - accuracy: 0.0153 - val_loss: 3.6394 - val_accuracy: 0.0057\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 2.8752 - accuracy: 0.0186 - val_loss: 3.6480 - val_accuracy: 0.0057\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8870 - accuracy: 0.0177 - val_loss: 3.6576 - val_accuracy: 0.0057\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.8970 - accuracy: 0.0190 - val_loss: 3.6711 - val_accuracy: 0.0057\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8844 - accuracy: 0.0186 - val_loss: 3.6803 - val_accuracy: 0.0057\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8955 - accuracy: 0.0173 - val_loss: 3.6929 - val_accuracy: 0.0057\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8975 - accuracy: 0.0190 - val_loss: 3.7065 - val_accuracy: 0.0057\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8719 - accuracy: 0.0184 - val_loss: 3.7198 - val_accuracy: 0.0057\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 2.8451 - accuracy: 0.0177 - val_loss: 3.7355 - val_accuracy: 0.0057\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8397 - accuracy: 0.0196 - val_loss: 3.7493 - val_accuracy: 0.0057\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8525 - accuracy: 0.0182 - val_loss: 3.7641 - val_accuracy: 0.0057\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8734 - accuracy: 0.0201 - val_loss: 3.7784 - val_accuracy: 0.0057\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 2.8549 - accuracy: 0.0201 - val_loss: 3.7922 - val_accuracy: 0.0057\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8469 - accuracy: 0.0176 - val_loss: 3.8054 - val_accuracy: 0.0057\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8770 - accuracy: 0.0192 - val_loss: 3.8185 - val_accuracy: 0.0057\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8531 - accuracy: 0.0182 - val_loss: 3.8330 - val_accuracy: 0.0057\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8841 - accuracy: 0.0177 - val_loss: 3.8465 - val_accuracy: 0.0057\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.8677 - accuracy: 0.0182 - val_loss: 3.8599 - val_accuracy: 0.0057\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8706 - accuracy: 0.0192 - val_loss: 3.8728 - val_accuracy: 0.0057\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8167 - accuracy: 0.0202 - val_loss: 3.8859 - val_accuracy: 0.0057\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8890 - accuracy: 0.0181 - val_loss: 3.9001 - val_accuracy: 0.0057\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8876 - accuracy: 0.0189 - val_loss: 3.9134 - val_accuracy: 0.0057\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8531 - accuracy: 0.0175 - val_loss: 3.9267 - val_accuracy: 0.0057\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8866 - accuracy: 0.0209 - val_loss: 3.9414 - val_accuracy: 0.0057\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8752 - accuracy: 0.0205 - val_loss: 3.9559 - val_accuracy: 0.0057\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8590 - accuracy: 0.0195 - val_loss: 3.9690 - val_accuracy: 0.0057\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8310 - accuracy: 0.0185 - val_loss: 3.9835 - val_accuracy: 0.0057\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.8664 - accuracy: 0.0179 - val_loss: 3.9972 - val_accuracy: 0.0057\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.8523 - accuracy: 0.0188 - val_loss: 4.0109 - val_accuracy: 0.0057\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8585 - accuracy: 0.0183 - val_loss: 4.0229 - val_accuracy: 0.0057\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8681 - accuracy: 0.0199 - val_loss: 4.0365 - val_accuracy: 0.0057\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.8441 - accuracy: 0.0180 - val_loss: 4.0503 - val_accuracy: 0.0057\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8724 - accuracy: 0.0184 - val_loss: 4.0660 - val_accuracy: 0.0057\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8718 - accuracy: 0.0195 - val_loss: 4.0805 - val_accuracy: 0.0057\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8755 - accuracy: 0.0196 - val_loss: 4.0924 - val_accuracy: 0.0057\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.8601 - accuracy: 0.0193 - val_loss: 4.1055 - val_accuracy: 0.0057\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8461 - accuracy: 0.0194 - val_loss: 4.1176 - val_accuracy: 0.0057\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.8547 - accuracy: 0.0191 - val_loss: 4.1310 - val_accuracy: 0.0057\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.8501 - accuracy: 0.0172 - val_loss: 4.1447 - val_accuracy: 0.0057\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.8520 - accuracy: 0.0197 - val_loss: 4.1583 - val_accuracy: 0.0057\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 2.8543 - accuracy: 0.0195 - val_loss: 4.1736 - val_accuracy: 0.0057\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 2.8214 - accuracy: 0.0187 - val_loss: 4.1856 - val_accuracy: 0.0057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_P0JJeOiLMb"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZG3tZQu2jx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f66fcb7b-db65-4993-e4f0-0c7bdc19aad8"
      },
      "source": [
        "# Plot loss per iteration\r\n",
        "\r\n",
        "plt.plot(r.history['loss'], label='loss')\r\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\r\n",
        "plt.legend()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2c1348f470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YNyYwlS21TR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "1d1aefa0-8123-4250-e126-7a8f9220ad99"
      },
      "source": [
        "# Plot accuracy per iteration\r\n",
        "\r\n",
        "plt.plot(r.history['accuracy'], label='acc')\r\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\r\n",
        "plt.legend()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2c144af9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGp5-_lKiPA5"
      },
      "source": [
        "# Create prediction model\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "1.   Because the training process and inference process (decoding sentences) are quite different, we use different models for both, albeit they all leverage the same inner layers.\r\n",
        "2.  An important thing to note is that you are making use of the same dense layer you created earlier - the same trained weights. If you use new layer, then it will have new random weights\r\n",
        "3.  Like the training model, the prediction model is made up of encoder and decoder layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv87yvybpua3"
      },
      "source": [
        "## Theory\r\n",
        "\r\n",
        "1.   Encode the input sequence into state vectors.\r\n",
        "2.   Start with a target sequence of size 1 (just the start-of-sequence character).\r\n",
        "3.   Feed the state vectors and 1-char target sequence to the decoder to produce predictions for the next character.\r\n",
        "4.   Sample the next character using these predictions (we simply use argmax).\r\n",
        "5.   Append the sampled character to the target sequence\r\n",
        "6.   Repeat until we generate the end-of-sequence character or we hit the character limit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOCKZcZFmaqZ"
      },
      "source": [
        "## Encoder Layer for generating initial states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq0AgOvIcfF6"
      },
      "source": [
        "# The encoder will be stand-alone\r\n",
        "# From this we will get our initial decoder hidden state\r\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu6TL52-mf1V"
      },
      "source": [
        "## Create 3 input layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddtVTPpvcgsg"
      },
      "source": [
        "# 3 input layers\r\n",
        "# you want to reuse the hidden state and the cell state\r\n",
        "\r\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,))\r\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,))\r\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\r\n",
        "\r\n",
        "# predict 1 word at a time, i.e. unigram\r\n",
        "decoder_inputs_single = Input(shape=(1,))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2FvG8tLm5RS"
      },
      "source": [
        "## Decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVC_pyH_ck-F"
      },
      "source": [
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4N5Cke9dFTA"
      },
      "source": [
        "# recall that you want to set the hidden state, cell state and x from the previous time step\r\n",
        "decoder_outputs, h, c = decoder_lstm(\r\n",
        "  decoder_inputs_single_x,\r\n",
        "  initial_state=decoder_states_inputs\r\n",
        ")"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOwu9bxxnyBk"
      },
      "source": [
        "## Save the state, which will be updated after each time step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muzaLM4_dSE8"
      },
      "source": [
        "# This allows the sampling model to predict the next sequences of words based on the current word\r\n",
        "decoder_states = [h, c]"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUIho-Mvnjlb"
      },
      "source": [
        "## Reuse the same trained dense layer from above\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oddzjj-CjKc"
      },
      "source": [
        "### This is the important step where you reuse the same trained weights\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SfieFqqnKDt"
      },
      "source": [
        "## Create the model, but do not compile it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaGyK3dyCsxW"
      },
      "source": [
        "# No need to compile since no training needed\r\n",
        "# you are merely using earlier trained weights\r\n",
        "\r\n",
        "# inputs: y(t-1), h(t-1), c(t-1)\r\n",
        "# outputs: y(t), h(t), c(t)\r\n",
        "decoder_model = Model([decoder_inputs_single, decoder_state_input_h, decoder_state_input_c], \r\n",
        "                      [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcAVMmgWnCJ5"
      },
      "source": [
        "## Map indexes back into real words\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4hYDsp3Efd3"
      },
      "source": [
        "# so we can view the results\r\n",
        "idx2word_eng = {v:k for k, v in word2idx_input.items()}\r\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnwzMQbTvVft"
      },
      "source": [
        "# Create the sampling function\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPD22biPBwPQ",
        "outputId": "12aa9353-8df4-4a90-fae5-9608beba5473"
      },
      "source": [
        "word2idx_outputs['<sos>']"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NE5RDvJEf-m"
      },
      "source": [
        "def decode_sequence(input_seq):\r\n",
        "  # Encode the input as state vectors.\r\n",
        "  states_value = encoder_model.predict(input_seq)\r\n",
        "\r\n",
        "  # Generate empty target sequence of length 1.\r\n",
        "  target_seq = np.zeros((1, 1))\r\n",
        "\r\n",
        "  # Populate the first character of target sequence with the start character.\r\n",
        "  # NOTE: tokenizer lower-cases all words\r\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\r\n",
        "\r\n",
        "  # if we get this we break\r\n",
        "  eos = word2idx_outputs['<eos>']\r\n",
        "\r\n",
        "  # Create the translation\r\n",
        "  output_sentence = []\r\n",
        "  for _ in range(max_len_target):\r\n",
        "    output_tokens, h, c = decoder_model.predict(\r\n",
        "      [target_seq] + states_value\r\n",
        "    )\r\n",
        "    # output_tokens, h = decoder_model.predict(\r\n",
        "    #     [target_seq] + states_value\r\n",
        "    # ) # gru\r\n",
        "\r\n",
        "    # Get next word\r\n",
        "    idx = np.argmax(output_tokens[0, 0, :])\r\n",
        "\r\n",
        "    # End sentence of EOS\r\n",
        "    if eos == idx:\r\n",
        "      break\r\n",
        "\r\n",
        "    word = ''\r\n",
        "    if idx > 0:\r\n",
        "      word = idx2word_trans[idx]\r\n",
        "      output_sentence.append(word)\r\n",
        "\r\n",
        "    # Update the decoder input\r\n",
        "    # which is just the word just generated\r\n",
        "    target_seq[0, 0] = idx\r\n",
        "\r\n",
        "    # Update states\r\n",
        "    states_value = [h, c]\r\n",
        "    # states_value = [h] # gru\r\n",
        "\r\n",
        "  return ' '.join(output_sentence)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0UDHb6GH97G"
      },
      "source": [
        "## Make Predictions\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLGJQpCVEieh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4a9b6b-1b9a-465b-f551-12b0e3e4348f"
      },
      "source": [
        "for i in range(4):\r\n",
        "  i = np.random.choice(len(input_texts))\r\n",
        "  input_seq = encoder_inputs[i:i+1]\r\n",
        "  translation = decode_sequence(input_seq)\r\n",
        "  \r\n",
        "  print('-')\r\n",
        "  print('Input:', input_texts[i])\r\n",
        "  print('Translation:', translation)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: <sos> We know.\tLo sabemos.\n",
            "Translation: <sos> <sos> <sos> <sos> <sos> <sos> <sos>\n",
            "-\n",
            "Input: <sos> Listen.\tEscuche.\n",
            "Translation: <sos> <sos> <sos> <sos> <sos> <sos> <sos>\n",
            "-\n",
            "Input: <sos> It's Tom.\tEs Tom.\n",
            "Translation: <sos> <sos> <sos> <sos> <sos> <sos> <sos>\n",
            "-\n",
            "Input: <sos> It rained.\tLlovi.\n",
            "Translation: <sos> <sos> <sos> <sos> <sos> <sos> <sos>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}